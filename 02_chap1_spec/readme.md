/sp.specify Write chapter 1 in Part 1 of the book. The title of the chapter will be "The AI Development Revolution: Disrupting the $3 Trillion Software Economy". 

The chapter is based on this video:

**[Watch: The $3 Trillion AI Coding Opportunity](https://www.youtube.com/watch?v=VlOAWvvjThU)**

The chapter will mainly focus on how AI coding is already actively changing how software gets built and how Software is Disrupting Itself. This chapter will motivate students to take the new developers as a opportunity not a threat.

We will also strongly put forward the fact that any CS class taught today at any major university is probably best seen as a historical relic from a bygone time. We are writing this book to fill this gap, and get developers ready for this new era.

These topics dont need to be covered in this chapter:
- why repos and PRs may need new abstractions; and where ROI is showing up first.
- They also cover token economics for engineering teams, the emerging agent toolbox, and founder opportunities when you treat agents as users, not just tools.

The above video and the following Overview videos should be included in this chapter:

**[Watch Overview Video in Urdu/Hindi](https://youtu.be/dnk5nP9hzHg)**

**[Watch Overview Video in English](https://youtu.be/3ZPIerZkZn4)**

In this chapter we will focus on these topics from the video:

---

## Abstract

**Abstract:** This paper examines the transformative impact of artificial intelligence on the software development industry, analyzing how AI coding tools are disrupting the entire development value chain. Drawing from recent industry insights, we explore the emergence of AI coding as the first major market for AI technology, its implications for the $3 trillion developer economy, and the fundamental shifts occurring in software development workflows. The paper discusses the evolution from traditional integrated development environments to AI-powered coding assistants, the rise of autonomous coding agents, and the restructuring of the entire software development lifecycle. Key findings indicate that every aspect of software development, from planning to deployment, is undergoing radical transformation, with significant implications for developer productivity, software customization, and the future structure of the technology workforce.

---

## 1. Introduction

The software development industry stands at a pivotal moment in its evolution. After decades of incremental improvements in programming languages, frameworks, and development tools, artificial intelligence is catalyzing a fundamental transformation in how software is created, maintained, and deployed. This revolution represents more than just an enhancement of existing tools; it signifies a complete reimagining of the software development lifecycle and the role of human developers within it.

The emergence of large language models and AI-powered coding assistants has created what industry observers identify as the first truly large market for AI technology. Unlike other AI applications that remain primarily experimental or narrow in scope, AI coding tools have achieved rapid commercial adoption and are generating substantial revenue growth. This paper analyzes this transformation, examining both the immediate disruptions occurring across the development value chain and the longer-term implications for the software industry.

The software development ecosystem, valued at approximately $3 trillion annually, encompasses not just the 30 million professional developers worldwide but also the expanding population of development-curious individuals including designers, product managers, and domain experts who increasingly engage with code. As AI tools lower the barriers to software creation, this ecosystem is experiencing unprecedented expansion and transformation, creating both opportunities and challenges for established players and new entrants alike.

## 2. The Scale and Significance of AI Coding

### 2.1 The $3 Trillion Developer Economy

To understand the magnitude of disruption that AI coding represents, it is essential to quantify the scale of the software development industry. Current estimates suggest approximately 30 million professional developers operate worldwide. Using a conservative valuation of $100,000 in generated value per developer annually, the aggregate value creation in software development reaches approximately $3 trillion. This figure represents the economic output of the seventh or eighth largest national economy globally, comparable to the GDP of France.

This $3 trillion figure likely underestimates the true scale of the software development economy for several reasons. First, it focuses solely on professional developers, excluding the growing population of development-adjacent professionals who increasingly write code as part of their roles. Designers now implement interactive prototypes, product managers write scripts for data analysis, and technical writers create documentation systems. Second, the figure does not account for the indirect economic value generated by software, which has become the fundamental infrastructure of modern business and society.

The remarkable claim emerging from this analysis is that a combination of AI startups developing coding tools and the large language models underlying them are effectively reshaping an economy equivalent to a major nation. The speed and scale of this transformation have few historical precedents. While previous technological shifts in software development, such as the transition from assembly language to high-level languages or the adoption of object-oriented programming, occurred gradually over decades, the current AI-driven transformation is unfolding in a compressed timeframe of mere years.

### 2.2 Software Disrupting Itself

The irony of the current transformation is that software, having disrupted virtually every other industry, now finds itself subject to radical disruption. For decades, software has been the primary engine of business transformation, reshaping industries from retail to manufacturing to finance. Digital technology has fundamentally altered how goods are produced, distributed, and consumed. Now, software development itself faces the same forces of creative destruction it has unleashed on other sectors.

This self-disruption manifests in several ways. Traditional software development methodologies, established over decades of practice, are being challenged by AI-augmented approaches. The skills and expertise that defined senior developers are being partially codified into AI systems, democratizing access to sophisticated programming knowledge. The very nature of software as a product is changing, with applications increasingly incorporating AI capabilities that allow them to adapt and extend themselves based on user needs.

Contrary to expectations that automation would reduce the need for software, the availability of AI coding tools is actually accelerating software production. Where previously software followed a software-as-a-service model, serving the needs of hundreds or thousands of users with a single implementation, AI tools enable a shift toward highly customized, individual software solutions. Users can now create bespoke applications tailored to their specific workflows, preferences, and requirements. This phenomenon of vibe coding, where individuals create personalized software tools, represents a fundamental expansion of the software market rather than a contraction.

## 3. Transformation of the Development Lifecycle

### 3.1 Disruption Across the Value Chain

The impact of AI on software development extends far beyond the coding phase that has received the most public attention. Every stage of the software development lifecycle is experiencing fundamental transformation. The traditional sequence of planning, design, implementation, testing, and deployment remains recognizable, but the nature of work at each stage is evolving rapidly.

During the planning phase, AI tools are beginning to assist in requirements gathering and system design. Natural language processing enables stakeholders to describe desired functionality in plain language, with AI systems translating these descriptions into technical specifications and architectural recommendations. This reduces the communication gap between business stakeholders and technical teams, potentially accelerating the planning process while improving alignment between requirements and implementation.

In the implementation phase, the most visible transformation is occurring. AI coding assistants range from simple autocomplete systems to sophisticated agents capable of implementing entire features based on high-level descriptions. These tools have achieved the fastest revenue growth of any startup sector in history, indicating both strong demand and genuine value creation. Developers report significant productivity gains, though the precise impact varies based on task complexity and developer experience.

Code review and testing, traditionally time-consuming manual processes, are being augmented by AI systems that can identify potential bugs, suggest improvements, and even generate test cases. These AI reviewers provide consistent standards enforcement and can catch subtle issues that human reviewers might miss, particularly in large codebases. However, questions remain about the role of human judgment in assessing code quality, maintainability, and architectural soundness.

Deployment and operations are also being transformed through AI-powered tools that optimize infrastructure configuration, predict and prevent failures, and automate routine maintenance tasks. The convergence of development and operations in the DevOps movement is being extended through AI capabilities that can manage increasingly complex distributed systems with minimal human intervention.

### 3.2 The Changing Role of Developers

Despite the transformative power of AI coding tools, the consensus among industry observers is that software developers will not disappear. However, the nature of their work is changing dramatically. The traditional image of a developer typing code line by line is increasingly outdated. Modern developers are becoming more like orchestrators or directors, managing AI agents and ensuring that generated code meets requirements for functionality, performance, and maintainability.

This shift requires a different skill set than traditional programming. Developers must become adept at prompt engineering, learning how to effectively communicate with AI systems to achieve desired outcomes. They need to understand system architecture and design patterns at a higher level, as they increasingly work with larger code units rather than individual functions. Critical thinking and judgment become more important, as developers must evaluate AI-generated solutions and make decisions about when to accept, modify, or reject automated suggestions.

The implications for computer science education are profound. Much of current curriculum focuses on syntax, algorithms, and low-level implementation details that AI tools now handle automatically. Universities and coding bootcamps face the challenge of reimagining their programs to prepare students for a development landscape that looks fundamentally different from just a few years ago. The focus is shifting from memorizing syntax to understanding higher-level concepts, from writing algorithms to evaluating and combining AI-generated solutions, from individual coding to managing complex systems composed of human and AI contributions.

Interestingly, the trend suggests that the total number of developers may actually increase rather than decrease. As coding becomes more accessible through AI tools, more people with domain expertise in fields like business, science, and design are incorporating programming into their work. This democratization of development creates a larger, more diverse developer population with different backgrounds and perspectives than the traditional programmer archetype.

## 4. The Rise of Autonomous Agents

### 4.1 From Assistants to Agents

The evolution of AI coding tools follows a clear trajectory from simple code completion to sophisticated autonomous agents. Early AI coding assistants, such as GitHub Copilot, provided intelligent autocomplete functionality, suggesting the next few lines of code based on context. While useful, these tools remained firmly under developer control, operating at the level of individual code fragments.

More advanced systems introduced the ability to generate entire functions or classes from natural language descriptions. Developers could describe desired functionality in comments or prompts, and the AI would produce working code. This represented a significant leap in abstraction, allowing developers to think at the level of features rather than individual statements.

The current frontier involves autonomous agents capable of implementing complete features or even applications with minimal human intervention. These agents can plan multi-step implementations, write code across multiple files, run tests, fix bugs, and iterate on solutions. They operate in environments that provide sandboxes for testing and validation, allowing them to verify their work before presenting results to human developers.

The question of when coding assistance becomes truly agentic is both technical and philosophical. At one extreme, a simple autocomplete tool clearly operates under direct human control. At the other extreme, a system that can take a high-level product description, design an architecture, implement all components, test the system, and deploy it to production represents genuine agency. The current generation of tools occupies a middle ground, with increasing autonomy but still requiring human oversight and guidance.

### 4.2 Multi-Agent Systems and Workflow Integration

An emerging pattern in AI-powered development involves multiple specialized agents working together, each focused on different aspects of the development process. One agent might handle code generation, another focuses on testing, a third reviews code for security vulnerabilities, and a fourth optimizes performance. This division of labor mirrors human development teams but operates at machine speed.

The coordination of multiple agents raises interesting questions about workflow design. Should agents operate sequentially, with each completing its task before passing work to the next? Or should they work in parallel, with sophisticated orchestration systems managing dependencies and conflicts? Current implementations experiment with both approaches, and optimal patterns likely vary based on project characteristics.

Another key consideration is whether code generation and code review should be performed by the same agent or different agents. Having separate agents provides checks and balances, with the reviewing agent potentially catching issues the generating agent missed. However, if both agents share the same underlying AI model and training, they may exhibit similar blind spots and biases. The effectiveness of multi-agent systems depends on how well they complement each other's strengths and compensate for weaknesses.

Integration with existing development workflows presents both opportunities and challenges. AI agents need access to version control systems, issue trackers, continuous integration pipelines, and other development infrastructure. They must understand project conventions, coding standards, and architectural patterns. Successfully integrating agents into established workflows requires careful design to avoid disrupting existing processes while maximizing the benefits of automation.


## 5. Opportunities for Entrepreneurs and Startups

### 5.1 The Most Disruptive Era in Development Tools

Industry observers identify the current period as possibly the best time in three to four decades to start a company in the software development tools space. Massive disruption creates opportunities for startups to challenge established incumbents and capture market share. When fundamental paradigms shift, existing market leaders often struggle to adapt quickly, creating openings for more agile competitors.

The example of GitHub Copilot illustrates this dynamic. Microsoft, through GitHub, had numerous advantages: relationships with leading AI model provider OpenAI, ownership of the dominant source code repository, control of a leading integrated development environment, and a world-class enterprise sales force. Despite these advantages, Microsoft faces intense competition from startups like Cursor and other AI coding tools. This demonstrates that even well-positioned incumbents can be challenged when technology fundamentally shifts.

The rapid revenue growth in the AI coding sector, potentially the fastest in startup history, validates the market opportunity. Developers have demonstrated willingness to pay for tools that meaningfully improve their productivity. Organizations recognize AI coding capabilities as competitive advantages worth investing in. This combination of strong user demand and organizational budget creates a favorable environment for new ventures.

However, the window of opportunity may not remain open indefinitely. As the market matures, consolidation likely occurs, standards emerge, and competitive dynamics stabilize. Entrepreneurs interested in this space benefit from moving quickly while fundamental questions about optimal approaches remain unsettled and customer preferences are still forming.

### 5.2 Strategic Directions for New Ventures

Entrepreneurs exploring opportunities in AI-powered development can pursue several strategic directions. One approach involves reimagining traditional development tools and workflows for the AI era. Version control, issue tracking, continuous integration, code review, and other established practices may benefit from fundamental reconceptualization rather than incremental improvement.

The key insight is that better AI-era versions of existing tools may look quite different from their predecessors. A better version control system for AI development might integrate agent workflows differently, handle large AI-generated commits specially, or provide new abstractions for understanding machine-generated code. Simply adding AI features to existing tool categories may miss opportunities for more radical innovation.

Another strategic direction involves building infrastructure specifically for AI agents rather than human developers. This represents a paradigm shift: treating agents as primary customers whose needs may differ significantly from human needs. Agents might benefit from specialized APIs, alternative context formats, optimized execution environments, or novel interaction patterns. Developers who deeply understand agent capabilities and limitations can create tools that maximize agent effectiveness.

Specific opportunity areas include providing better context for agents, developing faster specialized models optimized for coding tasks, creating improved sandbox environments, and building tools that help agents navigate complex development workflows. Each step of the traditional development lifecycle presents opportunities for AI-native innovation.

A third approach focuses on enabling the next wave of developers. As AI tools lower barriers to entry, more people with domain expertise but limited programming background will engage in software development. Tools designed for this audience, balancing power and accessibility, could unlock tremendous value by enabling domain experts to create specialized software for their fields.


## Conclusion

The transformation of software development through artificial intelligence represents one of the most significant technological shifts in recent decades. AI coding has emerged as the first truly large market for AI technology, validating years of investment and research while creating substantial economic value. The $3 trillion developer economy is being fundamentally restructured as every aspect of the software development lifecycle undergoes radical change.

Contrary to fears that automation would eliminate developer jobs, the evidence suggests that AI tools are expanding rather than contracting the software market. By lowering barriers to software creation, AI enables more people to develop custom solutions for their specific needs. The democratization of development, combined with the growing sophistication of AI agents, points toward a future with more software, more developers, and more diverse approaches to creating digital solutions.

The current period represents an unprecedented opportunity for entrepreneurs and established companies alike. The disruption of development tools and workflows creates space for innovation and competition. Startups challenging incumbents, established players adapting their offerings, and entirely new categories of tools emerging characterize this dynamic period. Success will favor those who understand both the capabilities of AI systems and the evolving needs of human developers.

Key lessons from this transformation include the importance of treating AI agents as customers with distinct needs, the value of context engineering for both human and machine developers, the opportunity to reimagine rather than merely augment existing tools, and the potential for self-extending software that adapts to user needs. Organizations and individuals who embrace these principles position themselves to thrive in the emerging development landscape.


The transformation is still in its early stages. The full implications will only become clear over time as technologies mature, best practices emerge, and societal adaptations occur. However, it is evident that we are witnessing a fundamental restructuring of how software is created, maintained, and deployed. This restructuring will have profound implications not just for the technology industry but for every sector that depends on software, which is to say, virtually all of modern economy and society.

For developers, the message is both challenging and encouraging. The nature of development work is changing rapidly, requiring adaptation and learning. However, the fundamental value of human developers is the ability to understand problems, exercise judgment, and ensure that technology serves human needs. These capabilities remain essential even as the mechanics of coding are increasingly automated. Developers who embrace AI as a tool for amplifying their abilities rather than viewing it as a threat position themselves to participate in and benefit from this transformation.

The AI development revolution is not just about making existing processes faster or cheaper. It represents a fundamental reimagining of what software development can be, who can participate in it, and what software can achieve. As we navigate this transformation, maintaining focus on creating genuine value, ensuring code quality and security, and preserving the essential role of human creativity and judgment will be critical to realizing the full positive potential of AI-augmented development.


The transcript for the video

**[Watch: The $3 Trillion AI Coding Opportunity](https://www.youtube.com/watch?v=VlOAWvvjThU)**

is attached here:

0:00
AI coding is the first really large market for AI. When do we say this is all agents? We
0:07
just at the end of the value chain. We're like, does this work or not work? Click yes or no. Agents uh more than
0:14
ever need an environment to run these things. Context engineering for both humans and agents. Every single part of
0:20
it is getting disrupted. It's not that you know there's just somebody writing code like your classical developers
0:25
being disrupted but but everybody along the value chain.
0:31
So we just launched this I think amazing um new dev stack for the AI coding
0:38
environment and I'm really really excited about this. Yeah. I mean the and let me let me s start with a very high order pitch why I think
The $3 Trillion Developer Economy
0:44
this is so incredibly exciting. I think AI coding is the first really large
0:51
market for AI, right? I mean, we've seen there's a ton of investment has flown and the question now to some degree is
0:56
where's the value, right? Why are we doing all this? AI coding is can create an incredible
1:03
amount of value. If you think about this, right, we have about 30 million developers worldwide roughly, right? Let's say each of them generates
1:10
$100,000 in value. the United States that may be low because many of them get paid a lot more but but internationally
1:16
it might be a little high but I think order of magnitude it holds so in aggregate the value we're creating here
1:22
is about 30 million times 100,000 so $3 trillion I will argue even more because that's
1:28
just developers but then there's also people who are development curious they're not developers maybe they're I
1:34
mean design engineering now it's a big thing every designers product managers you know write code dock writers yeah I mean there's so many
1:41
effects But if you just take the the $3 trillion figure, that's about the GDP of France, right? So So the the claim we're
1:47
making here, as crazy as it sounds, is that we're saying the entire population of the seventh or eighth, I think,
1:52
largest economy on the planet generates generates about as much value as a
1:58
couple of startups that are reshaping the AI software development ecosystem, plus the LLM underneath.
2:03
Yeah. Everything we see and touch and use nowadays are all software.
2:09
That's right. Yeah. So we've software has disrupted everything in the world and now software
2:16
itself is getting massively disrupted. Totally. And then uh what you mentioned in the blog post is really interesting
Software Disrupting Itself
2:22
just because like we now are more capable at using LM to generate code and
2:27
coding and produce software. But then as a result there's no it's not like it's less jobs. It's actually more and more
2:34
softwares being produced. Before maybe it's a SAS service, you know, uh catering to hundreds of people's needs
2:40
to thousands of people's needs. Now you can really just vibe code things software by one for one.
2:45
Yeah. Yeah. I vote I do that. Exactly. You do that. Exactly. And then I v code my own email filter, you know, I I don't do as
2:52
so much of using LM to reply to my email, but I have a filter where I categorize the labels, you know, things
2:58
like that. Only to some emails. Only to some emails. So the question the first question
How the AI Development Loop Is Changing
3:04
becomes like how do you think the development loop is shifting
3:09
I think the answer is complex and very very frankly it's so early I think in this AI revolution we don't have the
3:15
full answer yet right but I mean we we have we have our our little stack our little soft you
3:20
know software development life cycle post AI in in the blog post and I think the biggest learning from that is
3:26
probably that every single part of it is getting disrupted it's not that you know there's just somebody writing code like
3:32
your classical developers being disrupted but but everybody along the value chain is getting disrupted what's the most surprising part for you
3:38
what's the most disrupted field today in coding and what do you think it will be
3:43
like what AI will come after next so I think well we've seen the biggest growth I think safe to say in the in the
3:50
classic sort of coding IDE integrated coding assistance or more agent coding assistance right you know the cursors
3:55
and and and devins and and GitHub copilots and and cloud codes of the world right I I think that's the where
4:01
we see the most traction where we've seen incredible revenue growth quite possibly I mean I want to say that
4:08
segment possibly has the fastest revenue growth of any startup sector we've seen in the history of startups
4:14
um which is again incredible statement but the so I think this is currently the
4:20
vanguard right and everybody's aware of it we're seeing you know billion dollar uh you know acquires or or or or
4:26
takeover offers so that's um that's incredibly vibrant sector now which Which one is next? That's a really good
4:32
question. So to be very specific in a blog, you know, we wrote about the basic loops.
4:37
The basics is you plan, you code, you re you review. Yeah. Um where does LM coming? Where do you
4:44
think more of a loop will be disrupted? Like do you think the loop will still be the same as what we used to have the
Coding Assistants and the Fastest-Growing Startup Sector
4:51
basic or do you think it will look very different? I think at this point it's very hard to speculate about the end state, right?
4:56
But if if you let's assume you've seen the first email here. I I'll get there. But if you looked at
5:03
the first email sent over the internet, right, you can sort of predict that probably we'll have websites and these
5:08
things. Maybe if you're good, you can, right? And but but you know, as saying like, hey, the net effect of this is
5:13
that everybody can rent out their house uh and compete with hotels and this is going to be the biggest hotel company on the planet. You'd be like, well, that's
5:19
a little far-fetched, but but now we have Airbnb, right? So, so these secondary effects, I think, are really hard are really hard to guess. Um, look,
5:26
my my current hypothesis is I think we'll still have software developers. I think they're not going anywhere. Yeah. Right.
5:32
I think what they do will look completely different. Right. Right. Yeah. I think the CS education,
5:40
frankly, any CS class taught today at any major university is probably best seen as this historical relic from a
5:46
from a bygone time, right? I mean that this the the the the basic if you look at the best of breed startups what
5:52
they're doing you know the loop that the developer is in looks so different from what you did
5:58
before right you you have multiple agents that you're prompting that you're telling things you know and pull that back into UI you're trying to understand
6:04
what they did you're trying to get put them back on the rails it's a lot more thinking at a higher level I mean all of
6:09
coding sort of has been higher levels of abstractions but I think we're making a huge leap here so so how it's going to
What the Developer Workflow Looks Like with Agents
6:14
look like I have no idea my gut feeling is we'll probably have more develop velopers look this basic
6:20
plan execute cycle it's probably going to be some flavor of that that's still around is my guess but what do you think
6:26
one of the my top questions is that would this be a step-by-step loop or would this meshed into just one step so
6:34
one example is if I if my agent is writing the code um like do I still need
6:39
to review it or do I have another agent that just reviews it if it's the same agent you know like implementation
6:45
detail is one thing you can sep separate out the agent generating code from the agent you know uh reviewing code but
6:52
then if it's all agent both generating and reviewing code is it just the same step do we actually disag disagregate um
7:00
you know the step at process and have human in the loop whereas if as a human I uh write code
7:06
and I want agent to review code that makes sense to me um so I do wonder when do we pull out
7:13
something as this is an individual tool and individual step a agent takes care of and when do we say this is all agents
7:21
we just at the end of the value chain we're like does this work or not work click yes or no
7:27
I think the the time periods over which an agent can work autonomously will get longer
7:32
you know still if somebody says like look I want to write a complete ERP system you know for my uh you know
7:38
multinational enterprise go there's no way I could imagine that that'll just run and back come software that actually
7:45
fits the requirements and and in part. I think it's a problem that uh models are still very very far away from being able
7:50
to run autonomously for that long. But the other problem is like let's assume this was an all human team. We wouldn't
7:56
understand all the challenges yet at the beginning, right? We'd have to revisit the design. We have to revisit the architecture. It has cost implications
8:02
and so on. So at some point you sort of need to go back to the architects and the product managers and say hey we had
8:08
a plan A didn't quite work or we have found new challenges. So here's our updated plan A. Is is that the you know
8:14
at a plan B right? is is this what you want to do? Um so I I I think I think
8:19
the loop will still be there. The time scales will will probably change but yeah it's very very hard to guess right now.
8:24
Yeah. Another thing we start to see more often is um contrary to how much humans
Agents Gaining Tools and Autonomy
8:31
need to come and intervene in the loop. We actually start to give agents tools
8:36
for them to know what they have to do. Uh one example is this loop I see so so often like the agent wants to implement
8:43
say clerk o in their app now they need to go to mlify and contact 7 to say what
8:50
is the latest version of clerk and how can I implement it correctly and in what file I'm not going to copy paste it to you
8:58
know cursor or give it to the agent because I'm too lazy as a human now the agent should be able to call the API
9:03
themselves to put stuff in the context to make it work this is just one example of what behavior change we're seeing
9:10
because before as developers we're so used to go back to the docs and refer to the docs and tell the agent what to do.
9:16
Now agents can obviously so we cut out the middleman, right? We cut off the middleman. I don't need to route all these requests for the
9:22
agents anymore. And then I think there's other examples which is verification. Um
9:28
as a human before when I write code or review others people's code, I pull out the code and then the first thing I do
9:35
is actually not to review because I don't like reading code. I'm not a human compiler. The first thing I do is to
9:41
fork uh the change and see if it still works. If it doesn't work, I just do not review it. Nowadays, uh there are
9:48
opportunities to give um just agents a native environment to first see does
9:54
this work? Does the UI still look good? Do all the requests still check out? Absolutely. Uh did it break my build before the
10:01
human needs to come in and review. Maybe that, you know, manifests itself in part of the local development process. Maybe
10:08
manifest itself in the PR review process. But in any case, now agents uh
10:13
more than ever need an environment to run these things. When I used to write something just for myself, like a little script I need
Why Agents Need Their Own Runtime Environments
10:18
somewhere. In the past, I usually didn't include unit tests, right? For production code, it's different, but for just personal things, you know, it's like, yeah, it's a single developer. I
10:25
know what I'm doing here. With agents, I now start including unit test because they're so much easier to write and they
10:30
allow an agent, as you said, right, to understand if the changes that they did did broke anything else, right? And they
10:35
may not have the context, you know, how this originally was built anymore in an easy digestible form. So that's super
10:41
valuable. On the grand scheme of like how much economic value this generates, where in
10:47
the value chain do you think it's growing the fastest? Like you see right now where the agents is um producing so
10:54
much more value than other other areas, but what are the areas you feel like would be the next takeoff? So look, I'm I've I'm talking about a
11:01
hundred or so enterprises about this per year. just when we you know take our portfolio companies to them as potential
11:07
customers what I'm hearing from them is that the number one use case in terms of
Legacy Code Migration as the Killer AI Use Case
11:12
ROI right now is legacy code porting right it's not super surprising like one of the first papers in the space from
11:17
Google right they they wrote a fantastic paper on uh you know where they detailed on you know just doing very mundane
11:23
things like replacing a Java library across a very large codebase right not like millions of lines of code right so
11:28
it's a very large code base what do you consider as legacy stack what do you consider as new stack
11:34
Well, it really depends on you, but I mean for the banks, it's often cobalt or forrron to to Java. Cobalt. I haven't heard that word for a
11:40
long time. You know, I I actually wrote Cobalt code once in the '9s. It probably dates me at
11:47
this point, but they actually how are LLMs with Coobo? They're apparently extremely good. Um,
11:52
so surprised. So, here's the thing, right? One of the hardest thing if you implement code with LMS is just getting the specification
11:58
precise, right? if if I can specify something very precisely then usually the L can do a good job at implementing
12:04
it. So many of these companies do is they take legacy code, they have an LLM write a specification that fits the
12:11
legacy goal and then they say reimplement the specification and you may look at the code if the you know as a tiebreaker if if something is not
12:17
clear, right? And that seems to work incredibly well. So I'm hearing that today um I heard from several sources
12:23
now that you can get, you know, about a 2x speed up versus traditional um processes for that, right? And and
12:29
that's amazing, right? What this has led to is that actually of those enterprises that I've talked to, the majority says
12:35
they're currently accelerating like at least the the majority of those that are sophisticated about this, they're saying
12:41
they're accelerating their developer hiring, right? We don't know if this is a long-term trend, but right now they're basically saying, look, because we found
12:46
so many lowhanging fruit type projects where with a with a little bit upfront investment, we can then save
12:51
infrastructure costs. And that's super exciting. So I'm I'm you know what this will mean for the you know how how much
12:57
longer is the mainframe business going to be around or you know I don't know but but it's there's definitely a shift there where suddenly legacy code
13:03
migration is much much easier than it was before uh you know it's I think that they'll change a lot of the dynamics in
13:08
the sort of classic enterprise software space that's interesting I do wonder if we will get new mainframe code because now
13:16
because before no one knows how to program those things that could also be yes right and now you realize you can
13:22
program mainframe using natural language Yeah, totally. So, another possibility is that we get renaissance of like the underlying
13:28
legacy uh coding languages. And it's it's crazy to me how versatile
13:34
these coding assistants are, right? I mean, we're seeing them write CUDA kernels which like that is difficult
13:40
stuff to write, right? By any metric. Yeah, I've tried them with a language which basically has no usable training data
Rewriting the Software Stack with LLMs
13:45
set and they're still able to sort of abstract, you know, the with a couple of
13:50
examples um you know of how the code will have to look like. It's not perfect but so I I think it's it's a very very
13:57
broad technology for sure. recently it's just like what we were talking about before um code reviews because like to
14:04
your point um LMS are so good at coding and generating code sometimes it's
14:09
beyond our our comprehension will take more time to review the code than the coding agents like there's that's not a
14:16
controversial opinion just like how it is that's the reality yeah so it does make me wonder how our
14:22
development chain and steps are going to uh evolve from here how are we going to
14:28
do PRs when we can't possibly review thousands of lines of code as humans.
14:33
So, does that mean the right abstraction now is still code or does it mean the right abstraction now is for us to
14:38
review plans? If that's the case, is GitHub review still the right
14:44
abstraction for that? I think there's still a role for review in general. I think the question is will
14:51
humans do the review? Like right now, most of the code that LM generates, you
14:56
know, unless you're you if if you're deep in vibe coding territory, you're just like, "Oh, this is a one-off. I'm, you know, just want to try something
15:01
out." Maybe then you don't review it. You just sit accept and hope for the best. But but anything that you know, anything else, you do review the the I
15:08
still review the code line by line. You know, that said, we're starting to see really good tools that plug into your
15:13
backend system, your GitHub. Whenever a pull request comes in, they
15:18
analyze it, they comment on it, they point out security vulnerabilities, they point out that the spec is different from the implementation. Um, you know,
15:24
they they point out that this creates dependencies which may not be desired. They, you know, enforce coding guidelines. Um, which is very very
15:32
powerful, right? I haven't met anybody yet, and tell me if you have, but I haven't met anybody yet who basically
15:38
has said we we're going to rely purely on AI to review code, right? just
15:43
anything can go in if the AI checks off on it. Um but I have seen for example companies that are saying before we had
15:48
two developers review code and now it's one developer right and uh or you know cases where basically just the AI hangs
15:55
out in the in the GitHub you know discussion and comments on things you know if there's if they you know so you
The Future of Code Review and Verification
16:00
can basically delegate tasks like can you look at this like are we using this library somewhere else so basically can suddenly have somebody who can who can
16:07
help with these these tasks my hot take on this is actually if PR is supposed to give us a context as
16:13
developers on what the did these other coding agents or my colleagues uh you know change that I should be aware of. I
16:21
don't think code reviewing code is the right abstraction because it might be feature level it
16:27
might be performance level so now now it might just become a oneliner this you know this agent improve your cuda
16:36
implementation and I maybe I don't even know cuda but I know the improvement when I can verify it. Um, so the
16:44
question for me is, uh, do I still need to go to the PR and review every line or should I just be given, you know, uh,
16:51
two sentences to know how this works and the environment to test it out and now just
16:56
if it's the right two sentences that works? Yeah. Will the will the LM always pick the right two ones? I don't know yet.
17:02
Yeah, that's true. I mean, if you give it an environment, the question is like, can you verify the environment against
17:08
the two sentences? If the answer is yes, that would be easier to solve. of the answer is no. You know that's harder.
17:14
But I think there's a bigger picture here though which is that LLMs are also very good in generating the
17:21
documentation and description for the code. Right? So when I use something
17:26
like cursor for coding and you know it generates code I often ask it afterwards and now take the
17:32
internal documentation update it because the the internal documentation is important for me but but also for for
17:37
the coding agents because they want to be able to refer to it. You don't want every single time to take the entire codebase and stick it into the context
17:43
window. It's just massively inefficient and slow. So if instead you can just say like read this document that'll explain
17:48
to you the class hierarchy, right? And then based on that implement this new subclass. So it's much much faster
17:54
um to do and I think I think there's a real opportunity there to get to much better documented code than previously
18:01
right I mean you can almost a compiler is great and then it takes a high level abstraction translates it
18:06
into a lower level one but now we have the ability that if somebody had hand optimizes a lower level one we can use
18:12
that to update the higher level one that's true what is the new compiler in the age of AI
18:18
LLMs are sort of a compiler right in some way I mean they take a high higher level description and uh and fill it
18:25
down. I mean I think the big I guess what's missing is it doesn't have a natively have a environment compiler give you does this work or does
18:31
it does it compile or does it not compile it doesn't tell you does this work which is a very subject thing
18:37
I think it's right right and a like a compiler enforces
18:42
is a strict enforcement of certain things right you can I can rely on that I don't know I'm using Rust and things
18:48
will be typed right so so that's that's a huge step forward right then I can exclude certain bugs with an LM that's
18:54
not the case kind of the now that said you sort of wonder is this just an
Rethinking GitHub, Repos, and Developer Platforms
19:00
initial thing is this just a I mean LLMs over time like for example we can give LLM tools that allow them allows them to
19:08
syntactically parse code right and then now suddenly they can start reasoning above code they can ask are we sure that
19:14
the representation of object X is the same across these different you know modules even if they get serialized in
19:19
between or something like that right I don't mean to make this episode um disagregating GitHub. But GitHub is so
19:27
central to so much of our workflow, right? Everything goes through it from the social aspect of discovering what
19:33
other developers are doing to distributing the software. You can download things to keeping track of what you have
19:39
changed. Git whole integration with the build system, the back end. Yeah. Yeah. So now another interesting thing
19:45
we start to uh see is people use git repos very differently now. Before it
19:52
was like oh humans will make some changes we'll commit it and then other people will see it and then when you you know open a PR people see different
19:59
revisions. Now agents are doing so many changes it's kind of counterproductive
20:04
to commit everything and then uh repos usually have very uh low rate limits
20:11
because it's designed for humans to use. So now the question becomes what is the
20:16
new repo um like abstraction like that handles like a distributed like
20:22
infrastructure but also has caters to high frequency commits and sometimes
20:28
when agents doing these commits they don't even want to preserve this forever. is more like an intermediate
20:34
state step so that they can explore five different paths you know but then revert
20:40
to any of them and then when they're happy with it they come back to GitHub um so one one thing I've been playing
20:46
around with is uh there's this company called relays and then their docs has this repost feature where you can give a
20:53
repo to the uh agent the agent will you know come in stuff like very high frequency uh kind of works really well
20:59
with by coding agents and that has been such uch a great experience and in the wild I start to see people building this
21:05
internally too. It makes total sense. Look, if we completely change how humans write code,
21:13
right? Or we're shifting from humans to delegating the the most of the writing to agents. I think it would be foolish
21:19
to assume that the underlying services that were a good fit for the human world are still a good fit for this new agent
21:24
world, right? That that's almost certainly not the case, right? We can do better in our cases. Yeah, I think
21:30
you're completely right right for for source code repositories, we want something that's much more real time.
21:35
Honestly, I mean, imagine let's take this to the limit, right? Let's assume I have now just me personally running 100
21:41
agents in parallel that all try to implement features in my codebase. Yeah, we probably need some kind of coordination mechanism between them.
21:47
Then all all they're all not trying to edit the same file, right? You know, the rebase only carries you so far, right?
21:53
Um you just get too many um collision. They all need shared memory on the repo they're working on because they don't
21:59
want to reinstall the dependencies every time. That's right. Yeah. Exactly. And and so, you know, you probably need something that's much much more flexible and and
The Rise of Context Engineering for Humans and Agents
22:07
and more real time. And, you know, I we were still figuring out what that is. What Relay is doing that is is amazing.
22:12
And I think it's it's not just it's not just true for the for for GitHub. I mean GitHub is one of the big platforms we
22:18
use but you know take take the specification writing with you know say a conflence or Jira for example what you
22:23
could use there if you would develop these systems bottoms up with AI in mind
22:28
they would probably look very very different right I mean it's like you know should my story tracker have a function that looks at code and updates
22:34
stories accordingly then yeah that would be very natural right so I think and you can do I think we've seen this for
22:41
documentation right I mean something like Mintify looks very very different at the the documentation problem than
22:46
than than previous generations. I think we're seeing it for testing, we're seeing it for code, for PR reviews. It's
22:52
we're rethinking this entire stack and that's exciting, right? That's true. Another behavior change uh
22:58
we have seen which is really interesting because humans like developers were very lazy. Yeah.
23:03
So, uh if we don't have to read it, we do not read it. We only read the relevant parts in documentation. We only
23:09
skim through things. So the net new behavior we see all the time with you know documentation uh like hosted on
23:16
milifi is that users who are net new just go in and ask questions. Yeah.
23:22
And agents do not just ingest it anymore. They will actually just do a query against this context.
23:29
Yeah. So context engineering for both humans because we're our brains are like LM. We
23:34
need the context and agents who need context which is a very critical part. It's such a critical part of like
23:41
development from uh here point on and then the question becomes what are the other tools you think agents will need
23:49
like we had this huge you know market map from the blog uh and then there's
23:54
contrary to where you know all the mark previous market map um suggest which is like here are the developer tools now
24:01
there are agent tools to make better yeah and in some cases the same tool caters to both right I mean that's we need to
24:08
documentation for agents and humans. So look, um early days, but I think we're seeing a couple of big categories
24:14
emerge, right? I mean, um sandboxes are helpful to try out, you know, code snippets or or or build things.
The New Market Map of Agent Tools
24:20
How do you define a sandbox? I think we can record a whole episode on it, but we we and I think we will at some point,
24:26
but but the look at the you need an an environment with certain safety guarantees, right? where where LLMs
24:35
hallucinate. LLMs can be with clever, you know, if they use external sources,
24:41
they can potentially be maliciously prompted to do bad things. And you just want to have something that basically limits how much the blast radius if if
24:47
they if anything bad happens. I think we're seeing uh interesting search tools
24:53
and parsing tools like something like source graph or so, right? If if I have a if if I'm writing a couple of my code
24:58
in a couple of files, we don't need that. we have a really large code base, you know, and suddenly the question is,
25:03
look, we're looking for we we're trying to replace we're trying to add a parameter to a function in a library that's widely used. Where's this library
25:09
used? This is a really hard problem suddenly, right? I mean, it's like if you're in Python or so, you can import
25:15
something as something else. So, so like a a simple find operation will no longer find these things. You probably need syntactic parsing um to find those. So,
25:22
I think we're seeing documentation tools that are optimized for for agents and allow agents to look up um these things.
25:29
I think it's good for if an agent can do things like web search. Yeah. Right. So, you know, we're seeing companies in in
25:34
that space. What am I missing here? There's so many more. I think there's the other part of uh more we're seeing more specialized
25:40
models. Yeah. I mean, the the for things like code editing or, you know, re-ranking
25:46
files and things like that, right? That's that's definitely shaping up as a market. If you take a big step back, if
25:52
if we assume there's massive value creation here, that probably creates an opportunity to
25:58
create a very large number of startups. I mean, if you would have asked me 18 months back, I would have asked me 24
26:03
months back, I would have said like, look, dev tools, that's a smallest kind of market. How big can this be, right? That's not very exciting. If you ask me
26:09
today, it suddenly looks like this is, you know, a market that could go in the hundreds of billions of dollars, right?
26:15
In theory, could it go to trillion? I don't know. So, how many companies can you create in that space? I have no idea but but probably hundreds right and over
Multi-Agent Orchestration and the Cost of Coding
26:22
time it'll it'll you know it'll consolidate but um I expect this to be an ecosystem not a not a business model.
26:30
I have a fun question which is going forward. So when GitHub came out they have this uh commit charts. It's um it
26:39
was on t-shirts you know like people compare their commit charts people like commit specific messages. So the commit
26:46
charts look like uh like uh has a good graphics. What because before commit commits are
26:53
so tied to the value um developers bring like how many commits do you make? Uh
26:59
how many lines of code do you change? I mean we all know it's not the best proxy for value.
27:04
Yes. Not at all. Right. So what would be the next commit
27:09
chart on GitHub? What would that look like? What's the next that's a that's a basic question. Maybe
27:17
how many tokens you burn if you come to the office like look I burnt like 10 million tokens over the weekend. The
27:22
token burn could also be very ineffective prompting or conting.
27:28
Yeah, I just stuck my entire code base in the context window maybe. Is it the number of agents you use? Is
27:34
it that's even more gameable? What is the unit of value that's the
27:40
closest approximation to what you've delivered as value as developer? Non-cashed input tokens
27:48
might be too complicated. I don't know. Yeah, I'm taking this to a high level. The metrics how we evaluate software
27:55
development are changing, right? Where potentially a big complex refactoring
28:01
isn't that much work anymore because because I can let the LM do this and it's structurally easy. A specific
28:08
optimization in a fairly obscure area where the LLM has no training data, I may have to do by hand and it's vastly
28:13
more valuable. So yeah, it's complicated. Maybe it's number of apps that I've coded.
28:20
I think something else uh uh which is there's on the um market map agent tool
28:27
boxes there's actually a box I want to double click on uh there's the agent orchestration you can now use not just
28:34
one agent but multiple agents even different copies of the same agent for
28:39
them to parallelly do things. Yeah. What's the implication of this? What can
28:44
you do with multiple agents orchestrating them together that you couldn't do before? I mean, we're all
28:50
very ADHD developers. I mean, I think it's there's a couple of things work faster obviously, right? But
28:57
you can also try out multiple approaches in parallel and see which one works best. I've seen approaches where people, for example, they want to optimize a
29:03
certain code and they fire off a couple of agents with slightly different approaches and then just measure which one works best. I see.
29:08
And there's some startups proposing doing that in a more automated way even, right? where where you would just uh um
29:15
do this uh you know without human intervention you just say optimize this and then you know this gets kicked off in the background and the this all this
29:22
all takes a crazy amount of tokens at the end right so I mean by the way I think this is a really another really
29:28
interesting trend where 3 months ago I don't recall anybody talking about the cost of coding assistance
29:35
right yeah I mean three months ago honestly nothing right you go to Reddit forum on cursor so there was you know
29:41
pretty much nothing posted in there today. That's one of the number one topics in those forums. Maybe the number
29:47
one topic, right? Because I think we figured out how with high powered reasoning models and very large context
29:53
windows, we can have single tasks that suddenly cost dollars. Not
29:59
sure about tens of dollars, but at least, you know, dollars is very, very doable. And that adds up, right? It
30:06
depends, you know, if you're a super high high-end programmer, maybe it doesn't matter. if anybody else a couple of dollars an hour you know that's um
30:13
that's a substantial expense if you're in a lowcost location it may end up
30:18
costing more than what you're making it used to be that if I was writing software I
From Token Burn to Developer Productivity Metrics
30:26
oversimplifying slightly had one expense which is people right okay they needed uh you know a laptop and and and some
30:32
connectivity in an office but but in the grand scheme of things the cost that really mattered you know at least in in
30:37
the you know more high high cost locations was the the compensation of the person. That seems to have changed
30:44
now. We suddenly have infrastructure cost for a software engineer, right? They need a the constant feed of of LM
30:50
tokens to keep them happy, otherwise they're not productive. They'll probably change the industry somehow, right? And
30:56
I think I'm not sure we understand how, right? We know people will be building more. That's for sure. That's right.
31:02
And the question becomes, does building more correlate with more tokens burned to some extent, right? And I met so many
31:10
great engineers who are burning, you know, like they're the top token burning engineer of the company and they're just
31:15
so effective. Yeah. Have like two laptops side by side and, you know, run coding agents that way.
31:21
It's like the shift from digging versus driving the the excavator that does the
31:26
digging research, but that changes the industry, right? Probably the person is slightly happier, right? I mean, that's what happened in
31:32
that case. You need less of them. People will but but you can also build a lot more, right? So I think it'll it'll
31:38
change the industry. Then I think there's more customization to software. To your point about building more um because there's always one
31:45
bespoke tool for any business out there. Um you know there's HR software. It covers
31:53
80% of what every company needs. The 20% like I know this really well because I
31:58
used to be a PM on these enterprise softwares. We build APIs. So the internal teams build their version.
32:04
That's right. Yeah. And then now we just have turtles all the way down. Like we build the base layer, the internal team
32:10
builds next layer and then developers are like ah still doesn't work. Let me build something else. But now with uh
32:16
VIP coding, I actually think customization is just easier and easier than ever. You may or may not even need
32:22
a centralized team to build that layer using, you know, a commercial solutions APIs. You can just code it up yourself
32:29
like what I did. Um, something I've been thinking about is what's the next workflow or
32:35
automation going to be? Like before we have, you know, Zapier and other great RPA tools of the world to make it work.
32:42
Now with BIP coding, obviously you still need to know code to some extent to make it work. How would that change? I think
32:49
we'll just end up having more workflows running soft somewhere. Um um the
32:56
question is like how can we unlock the net new uh like new developers who are not traditionally technical but now are
33:02
writing code to implement these maybe they don't need a graphical interface or if they do need an graphical interface
33:09
it's can be represented by JSON which is more agent friendly yeah in fact we tend to see almost
33:16
self-extending software right software where a user with a prompt can add
33:22
additional function funality. Yeah, that's so true. Yeah. Yeah. And which is crazy. Is that a trend? Is
Customization, Vibe Coding, and Self-Extending Software
33:27
that I think it is a trend. Will the next version of Microsoft Word or not the next version but maybe a couple vers down the road have a have a
33:34
you know add feature button in the the help menu? So software I think the takeaway point is software is having more affordance
33:41
than before because of the ability to integrate LM. And what I mean by that is before if I'm a marketing company uh I
33:48
ship a feature so people can visualize six charts. Yeah. Now I ship a chat session with the LM.
33:55
LM can reach back to my data and the LMS's generate code to materialize
34:01
whatever charts people want to see. So it's more than six. It's like thousands and hundreds and thousands uh of things
34:08
that people will want to see. So the interaction model between end user of the marketing software um and LM
34:16
becomes it can materialize net new features using their own words. So prompt which is very different from
34:23
before software teams they're shipping feature by feature. So now with all that, what do you think
34:30
people want to build? Uh or what do you think developers should be building? What do you think the world needs?
34:36
It it needs so much. I mean there's two things I'm sure about. One is this is
34:43
I would say over the last three four decades probably the best moment in time to start a company in the development
34:49
space. Right? It's if you have such a massive disruption, this is what this is what allows a startup to really grow and
34:56
and and and scale and and pick a pick a battle with the with the incumbents. I think we've seen that with you know GitHub co-pilot for Microsoft first in
35:02
the market relationship to the number one model company with open AI you know they have
35:08
the number one source code repo they have the number one IDE they have the best enterprise salesforce and still you know we're seeing um you know a swarm of
35:15
competitors that that are all doing very very well against them. So, so this is this is really um the time. The second
35:21
thing that I'm 100% convinced of is that the good ideas are not coming from the VCs but from the entrepreneurs. Um so,
35:28
you know, if you spot an opportunity to do something better with AI right now,
35:34
you can probably add value, right? And then it's about fast execution, it's about building a great team. Um you
35:40
know, it's uh it's about running very very fast. But uh you know my prediction is I think we will we will fund
35:48
dozens of companies in this space um going forward. Yeah, we are excited to just fund the
35:54
next wave of startup. But if you're looking for ideas, here are two general directions. The first one is what are
What Founders Should Build in the AI Dev Era
36:01
the traditional workflows that you can now reinvent. It might not be one to one. So like a better git may not be git
36:08
exactly. It might be git and something else, right? And then if you just map out the value chain like what we have on
36:14
the blog post, you can pick a box and decide what you want to do with it. I think that's right. Yeah, that's one way to do it. Uh the other
36:20
way to do it is very differently from before like as product people we used to
36:26
uh only build for humans, other developers. Now we actually build a lot for the agents. Agents are the
36:33
customers. Does the agent need a better context? That's right. You should build for that. Does the
36:38
agent want, you know, lower latency for certain models? Well, there are companies shipping, you know, code apply
36:43
models that, you know, operates way faster with higher accuracy. That's also a need. And when you look into where
36:50
agents don't yet work, there's just plenty of things to work to work on. uh you know from uh just like easily
36:57
resumable sandbox I know there are great companies already building that or from to like how do you enable the agent to
37:05
kind of smash PR review process with the development process there's just so much more there to reinvent how agents could
37:12
work so treat agents as your customer yes and build for them the classic infrastructure right
37:19
absolutely no I think I think this is really an amazing time to start a company in this space Yeah.



